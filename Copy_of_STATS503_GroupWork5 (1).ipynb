{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P93PjjqPGWs1"
      },
      "source": [
        "# **STATS 503, Group Work Assignment 5: Cross validation**\n",
        "\n",
        "**Instructions:** During lab section, and afterward as necessary, you will collaborate in two-person teams (assigned by the GSI) to complete the problems that are interspersed below. The GSI will help individual teams encountering difficulty, make announcements addressing common issues, and help ensure progress for all teams. **During lab, feel free to flag down your GSI to ask questions at any point!** Upon completion, one member of the team should submit their team's work through Canvas as html.\n",
        "\n",
        "**credits:** Roman Kouznetsov, adapted from notes from Gang Qiao."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5NokVXAGWs7"
      },
      "source": [
        "# Getting started\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kql1Yf8XGWs7"
      },
      "source": [
        "In this assignment, we will explore logistic regression and $k$-fold cross validation. In $k$-fold cross-validation, we partition a dataset into $k$ equally sized non-overlapping subsets $S$. For each subset $S_i$, a model is trained on $S\\backslash S_i$ and evaluated on $S_i$. The cross-validation estimator of the prediction's error is the average of the prediction errors obtained on each fold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnBgZRkPGWs8"
      },
      "source": [
        "Let's start with simple example that will help us understand how CV works. We'll first import the relevant packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "i8WmEa65GWs8"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4UuA4DjGWs-"
      },
      "source": [
        "For demonstration purposes, let's create a synthetic binary classification dataset using scikit-learn's `make_classification` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "P2F9Pc-SGWs_"
      },
      "outputs": [],
      "source": [
        "# Generate a synthetic binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCZKz4fFGWtA"
      },
      "source": [
        "We'll look at two ways to do cross-validation.  First we'll do it \"by hand.\" Then we'll show how sklearn makes it easy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wEnQ9pDGWtA"
      },
      "source": [
        "# K-fold CV by hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ9JDfTTGWtA"
      },
      "source": [
        "First, we divide the data into 10 parts (a.k.a. folds)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "Pxmt83EyGWtB"
      },
      "outputs": [],
      "source": [
        "n_splits = 10 # 10-fold\n",
        "rng = np.random.default_rng(0) # make a random number generator with fixed seed\n",
        "permutation = rng.permutation(len(X)) # create a shuffling of the indices of our data\n",
        "splits = np.split(permutation,n_splits) # make folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "dTrUG9IKGWtB",
        "outputId": "f2d5ab67-71f1-4fd0-d243-43e7995a95e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([290, 277, 360, 524, 462, 789, 908, 493, 818, 251, 623, 123, 781,\n",
              "       589, 874, 304, 869, 746, 576, 811, 433, 837,  37, 161,  58, 560,\n",
              "       643, 965, 163,  64, 475, 838, 168, 659, 109,  41, 756, 596, 303,\n",
              "       763, 101, 703, 120, 531, 366, 553, 548, 575, 731, 470, 578, 660,\n",
              "       551, 417, 716, 911, 227, 587, 872, 185, 513, 866, 321, 418, 760,\n",
              "       820, 119, 952,  24, 606, 170, 278, 514,  15, 155, 367, 828,  92,\n",
              "        55, 897, 118, 791, 701, 145, 860, 645, 620, 778, 497, 794, 246,\n",
              "       842,  80, 646, 225, 951, 482,  20, 343, 250])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "# e.g., these are the *indices* of the datapoints \"fold 3\"\n",
        "splits[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "YZ_jrZOPGWtC",
        "outputId": "9b5fbe0b-e6f6-407a-aafc-7d49da9344b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "# and these are the y values for the corresponding samples\n",
        "y[splits[3]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G07HGg1PGWtC"
      },
      "source": [
        "Now, we'll assess predictive performance 10 times.  Each time we'll hold out a different fold and use the rest of the data for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "9qnRHQyKGWtD"
      },
      "outputs": [],
      "source": [
        "# we'll look at two metrics of predictive performance,\n",
        "# and store the results in these arrays\n",
        "missclass = np.zeros(len(splits))\n",
        "aurocs = np.zeros(len(splits)) # since this is binary classification, we can assess via auroc\n",
        "\n",
        "# iterate through folds\n",
        "for i in range(len(splits)):\n",
        "    # create test/train split for this held-out fold\n",
        "    s = list(splits) # copy list\n",
        "    test = s.pop(i) # pop out the ith fold\n",
        "    training = np.concatenate(s) # combine all remaining data for test\n",
        "\n",
        "    # fit model\n",
        "    model = LogisticRegression() # make estimator\n",
        "    model.fit(X[training], y[training]) # fit estimator using the training data\n",
        "\n",
        "    # assess metric for predictive performance using test data\n",
        "    missclass[i] = np.mean(model.predict(X[test])!= y[test]) # get misclassification on test data\n",
        "    aurocs[i] = sklearn.metrics.roc_auc_score(y[test], model.predict_proba(X[test])[:, 1]) # get auroc on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "LPVmEgICGWtD",
        "outputId": "229be2f5-a4be-4634-ad3c-ec342a78f6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.15, 0.15, 0.16, 0.1 , 0.21, 0.13, 0.11, 0.09, 0.15, 0.12])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "missclass # misclassification rate for each of the 10 test/train splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "6slDYasUGWtD",
        "outputId": "57235ed2-a964-41d7-d621-14e643367336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89783654, 0.90381494, 0.91304348, 0.93427036, 0.91666667,\n",
              "       0.90868506, 0.9696    , 0.96025692, 0.93830128, 0.95392628])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "aurocs # auroc for each of the 10 test/train splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "4IePmQ0NGWtD",
        "outputId": "b88c4729-e6b1-48c1-a5c5-58d959cd37d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean misclassification rate: 0.1370, plus minus 0.0105\n",
            "Auroc: 0.9296, plus minus 0.0076\n"
          ]
        }
      ],
      "source": [
        "# report conclusions: mean(scores) pm sqrt(tau^2/K)\n",
        "print(f\"Mean misclassification rate: {missclass.mean():.4f}, plus minus {np.sqrt(missclass.var()/n_splits):.4f}\")\n",
        "print(f\"Auroc: {aurocs.mean():.4f}, plus minus {np.sqrt(aurocs.var()/n_splits):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkdKmBTEGWtE"
      },
      "source": [
        "# K-fold CV using `sklearn.model_selection`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "texEqGz5GWtE"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLOeFM5ZGWtE"
      },
      "source": [
        "Setup the $k$-fold cross-validation configuration. For example, using 10 folds...\n",
        "* `n_splits=10` means 10-fold\n",
        "* `shuffle=True` meaning random folds\n",
        "* `random_state=42` means we'll get the same random folds each time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "QpdtjKmjGWtF"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=10, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "ylaPPJhcGWtF",
        "outputId": "cfd4c2c2-455f-4113-9c32-90c9e4713907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "split 0\n",
            "   test:   [ 10 23 30 39 54 59 63 66 67 70 ...]\n",
            "   train:  [ 0 1 2 3 4 5 6 7 8 9 ...]\n",
            "\n",
            "split 1\n",
            "   test:   [ 25 44 55 60 72 78 86 110 120 137 ...]\n",
            "   train:  [ 0 1 2 3 4 5 6 7 8 9 ...]\n",
            "\n",
            "split 2\n",
            "   test:   [ 2 3 5 7 9 29 31 33 49 65 ...]\n",
            "   train:  [ 0 1 4 6 8 10 11 12 13 14 ...]\n",
            "\n",
            "split 3\n",
            "   test:   [ 0 6 28 41 56 69 73 79 90 108 ...]\n",
            "   train:  [ 1 2 3 4 5 7 8 9 10 11 ...]\n",
            "\n",
            "split 4\n",
            "   test:   [ 11 12 18 24 42 43 51 61 74 83 ...]\n",
            "   train:  [ 0 1 2 3 4 5 6 7 8 9 ...]\n",
            "\n",
            "split 5\n",
            "   test:   [ 15 19 22 38 46 50 57 68 75 93 ...]\n",
            "   train:  [ 0 1 2 3 4 5 6 7 8 9 ...]\n",
            "\n",
            "split 6\n",
            "   test:   [ 8 16 17 26 36 37 45 48 53 103 ...]\n",
            "   train:  [ 0 1 2 3 4 5 6 7 9 10 ...]\n",
            "\n",
            "split 7\n",
            "   test:   [ 112 122 123 129 143 146 147 183 186 197 ...]\n",
            "   train:  [ 0 1 2 3 4 5 6 7 8 9 ...]\n",
            "\n",
            "split 8\n",
            "   test:   [ 4 14 27 32 35 40 47 52 62 64 ...]\n",
            "   train:  [ 0 1 2 3 5 6 7 8 9 10 ...]\n",
            "\n",
            "split 9\n",
            "   test:   [ 1 13 20 21 34 58 71 80 87 91 ...]\n",
            "   train:  [ 0 2 3 4 5 6 7 8 9 10 ...]\n"
          ]
        }
      ],
      "source": [
        "# look at folds generated by this cross-validation splitter\n",
        "for i, (train, test) in enumerate(cv.split(X)):\n",
        "    # this automatically gives you the train indices and test indices\n",
        "    # without having to construct them yourselves by combining folds\n",
        "    print(f'\\nsplit {i}')\n",
        "    print('   test:   [', ' '.join(test[:10].astype('U')),'...]') # test indices\n",
        "    print('   train:  [', ' '.join(train[:10].astype('U')),'...]') # train indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhRUZSnUGWtF"
      },
      "source": [
        "In fact, you don't even have to run the for loop yourself!\n",
        "\n",
        "With a single call to cross_val_score, we can evaluate the model using cross-validation. Here, we'll use accuracy as the performance metric, but you can choose other metrics like precision, recall, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "6SnRg4HeGWtF",
        "outputId": "67af1aab-3195-4d82-b467-86c7bf6c6538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.87, 0.86, 0.83, 0.89, 0.88, 0.86, 0.85, 0.87, 0.9 , 0.86])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "# Calculate accuracies across folds\n",
        "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "0vfWt2OLGWtF",
        "outputId": "ff31d507-0264-4f9c-f146-627f6efc82f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.8670, plus minus 0.0060\n",
            "Mean misclassification rate: 0.1330, plus minus 0.0060\n"
          ]
        }
      ],
      "source": [
        "print(f\"Mean accuracy: {scores.mean():.4f}, plus minus {np.sqrt(scores.var()/len(scores)):.4f}\")\n",
        "print(f\"Mean misclassification rate: {1-scores.mean():.4f}, plus minus {np.sqrt(scores.var()/len(scores)):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PveolAuGGWtF"
      },
      "source": [
        "Note that conclusions are not exactly the same, because CV used different splits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcYBSejGGWtG"
      },
      "source": [
        "If you want to use multiple metrics, use skelarn.cross_validate instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "c-KLzExsGWtG",
        "outputId": "8d927422-c9b9-4886-db8b-944ec3cc3dd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fit_time  score_time  test_accuracy  train_accuracy  test_roc_auc  \\\n",
              "0  0.017527    0.005358           0.87        0.874444      0.910879   \n",
              "1  0.017630    0.005205           0.86        0.880000      0.926250   \n",
              "2  0.004290    0.004195           0.83        0.881111      0.900641   \n",
              "3  0.004339    0.004414           0.89        0.872222      0.942222   \n",
              "4  0.004392    0.004926           0.88        0.877778      0.951600   \n",
              "5  0.004527    0.009968           0.86        0.876667      0.939382   \n",
              "6  0.004395    0.004373           0.85        0.883333      0.910364   \n",
              "7  0.005307    0.004638           0.87        0.880000      0.890405   \n",
              "8  0.005234    0.004553           0.90        0.870000      0.961851   \n",
              "9  0.005265    0.005287           0.86        0.876667      0.958788   \n",
              "\n",
              "   train_roc_auc  \n",
              "0       0.937207  \n",
              "1       0.936828  \n",
              "2       0.939317  \n",
              "3       0.934140  \n",
              "4       0.933526  \n",
              "5       0.934303  \n",
              "6       0.937373  \n",
              "7       0.939992  \n",
              "8       0.932240  \n",
              "9       0.932327  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67a014ca-ceeb-4d56-8b17-fcf813dd366e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_roc_auc</th>\n",
              "      <th>train_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.017527</td>\n",
              "      <td>0.005358</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.874444</td>\n",
              "      <td>0.910879</td>\n",
              "      <td>0.937207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.017630</td>\n",
              "      <td>0.005205</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.926250</td>\n",
              "      <td>0.936828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.004290</td>\n",
              "      <td>0.004195</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.881111</td>\n",
              "      <td>0.900641</td>\n",
              "      <td>0.939317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004339</td>\n",
              "      <td>0.004414</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.872222</td>\n",
              "      <td>0.942222</td>\n",
              "      <td>0.934140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004392</td>\n",
              "      <td>0.004926</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.877778</td>\n",
              "      <td>0.951600</td>\n",
              "      <td>0.933526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.004527</td>\n",
              "      <td>0.009968</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.876667</td>\n",
              "      <td>0.939382</td>\n",
              "      <td>0.934303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.004373</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>0.910364</td>\n",
              "      <td>0.937373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.005307</td>\n",
              "      <td>0.004638</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.890405</td>\n",
              "      <td>0.939992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.005234</td>\n",
              "      <td>0.004553</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.961851</td>\n",
              "      <td>0.932240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.005265</td>\n",
              "      <td>0.005287</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.876667</td>\n",
              "      <td>0.958788</td>\n",
              "      <td>0.932327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67a014ca-ceeb-4d56-8b17-fcf813dd366e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67a014ca-ceeb-4d56-8b17-fcf813dd366e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67a014ca-ceeb-4d56-8b17-fcf813dd366e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b8a2ebe7-c015-4df6-b2e1-33111934628f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8a2ebe7-c015-4df6-b2e1-33111934628f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b8a2ebe7-c015-4df6-b2e1-33111934628f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f50ff2a7-994a-47d1-8ead-28dc940e5a9b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f50ff2a7-994a-47d1-8ead-28dc940e5a9b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005437433109137927,\n        \"min\": 0.004290342330932617,\n        \"max\": 0.01762986183166504,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0052337646484375,\n          0.01762986183166504,\n          0.004526853561401367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0016933118023778075,\n        \"min\": 0.004195451736450195,\n        \"max\": 0.009968280792236328,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.004552602767944336,\n          0.005204677581787109,\n          0.009968280792236328\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02002775851439975,\n        \"min\": 0.83,\n        \"max\": 0.9,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.87,\n          0.86,\n          0.85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004132576593411357,\n        \"min\": 0.87,\n        \"max\": 0.8833333333333333,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.88,\n          0.8766666666666667,\n          0.8744444444444445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025246068868239237,\n        \"min\": 0.890405459654757,\n        \"max\": 0.9618506493506493,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9618506493506493,\n          0.9262499999999999,\n          0.939381774387796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0027948862633211807,\n        \"min\": 0.9322398055950688,\n        \"max\": 0.9399923947237161,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9322398055950688,\n          0.9368280632411068,\n          0.9343032529840831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "# info for each split\n",
        "results = pd.DataFrame(\n",
        "    sklearn.model_selection.cross_validate(model, X, y, cv=cv,\n",
        "                                           scoring=('accuracy','roc_auc'),\n",
        "                                           return_train_score=True)\n",
        "    )\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "rOG8yYkhGWtG",
        "outputId": "e14aa1e3-37fa-470e-b8f2-6e361e2aa822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auroc: 0.9292, plus minus 0.0080\n",
            "Accuracy: 0.8670, plus minus 0.0063\n"
          ]
        }
      ],
      "source": [
        "print(f\"Auroc: {results.test_roc_auc.mean():.4f}, plus minus {np.sqrt(results.test_roc_auc.var()/len(results)):.4f}\")\n",
        "print(f\"Accuracy: {results.test_accuracy.mean():.4f}, plus minus {np.sqrt(results.test_accuracy.var()/len(results)):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhozS4sWGWtG"
      },
      "source": [
        "Note the results also include train performance (because we set `return_train_score=True`).  Can sometimes be interesting to see discrepancy between train and test performance.  Usually train performance is a bit better.  If train performance is *a lot* better your estimator may have \"too much flexibility\" (though sometimes you may also be experiencing so-called \"benign overfitting\" in which case your estimator is actually just fine...).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "dA_OVFIVGWtG",
        "outputId": "5ed5b127-5b45-4199-834d-3265e715d952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train auroc: 0.9357, plus minus 0.0009\n",
            "Train accuracy: 0.8772, plus minus 0.0013\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train auroc: {results.train_roc_auc.mean():.4f}, plus minus {np.sqrt(results.train_roc_auc.var()/len(results)):.4f}\")\n",
        "print(f\"Train accuracy: {results.train_accuracy.mean():.4f}, plus minus {np.sqrt(results.train_accuracy.var()/len(results)):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n59mem4LGWtG"
      },
      "source": [
        "# Compare with another estimator (using same splits!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "KUBDR_gxGWtI",
        "outputId": "b7d9b374-cb8d-4d4c-f5b5-8e284413194d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.8120, plus minus 0.0110\n"
          ]
        }
      ],
      "source": [
        "model2 =  KNeighborsClassifier(5)\n",
        "scores2 = cross_val_score(model2, X, y, scoring='accuracy', cv=cv,n_jobs=-1) # note, using same folds, cv\n",
        "\n",
        "print(f\"Mean Accuracy: {scores2.mean():.4f}, plus minus {np.sqrt(scores2.var()/len(scores2)):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYt0NkEgGWtI"
      },
      "source": [
        "It seems that 5-NN is worse, by a margin that is well in excess of the spread."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DijycjR9GWtI"
      },
      "source": [
        "# Bias-variance tradeoff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBnSRZ65GWtI"
      },
      "source": [
        "It is very helpful to think about bias-variance tradeoff in cross-validation. In CV, the number of folds to use (the value of $k$) is an important decision. Imagine repeating the learning procedure on multiple datasets. The lower the value for $k$, the higher the bias in the error estimates and the less variance **across datasets**. Conversely, when $k$ is set equal to the training+val sample size, the error estimate is then very low in bias but has the possibility of high variance **across datasets**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15khN27MGWtI"
      },
      "source": [
        "Why? Some intuitions (but not mathematically rigorous proof) here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWe9Cyz2GWtY"
      },
      "source": [
        "While there is no overlap between the test sets on which the models are evaluated, there is overlap between the training sets for all $k>2$. The overlap is largest for leave-one-out cross-validation. This means that the learned models are correlated, i.e. dependent, and the variance of the sum of correlated variables increases with the amount of covariance:\n",
        "$\n",
        "Var(\\sum_i X_i) = \\sum_i \\sum_j Cov(X_i, X_j).\n",
        "$\n",
        "Therefore, leave-one-out cross-validation has large variance in comparison to CV with smaller $k$. To summarize, larger $k$ means less bias towards overestimating the true expected error (as training folds will be closer to the total dataset) but higher variance and higher running time (as you are getting closer to the limit case: Leave-One-Out CV)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvjArbI3GWtZ"
      },
      "source": [
        "For more fun facts and simulation about bias-variance tradeoff and cross validation, please see [this post](https://stats.stackexchange.com/questions/61783/bias-and-variance-in-leave-one-out-vs-k-fold-cross-validation/357749#357749)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Group Work 5 (30 points)\n",
        "\n",
        "But WHY do we even bother with cross-validation? What is the point?\n",
        "\n",
        "In this group work assignment, you'll perform K-fold cross validation on several classification models on the NHANES dataset. Additionally, you will be asked to write answers to explain WHY we do the things we do. Please feel free to ask instructors for guidance if cross-validation is still new to you."
      ],
      "metadata": {
        "id": "pdnTWktd2Eb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 1: Dataset Setup (1 point)\n",
        "\n",
        "Our favorite (and only) dataset we have used in the group work assignments is back! Please take the appropriate time to load in the 3 NHANES datasets."
      ],
      "metadata": {
        "id": "EvIGjZCn4NEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hdl = pd.read_sas('HDL_L.xpt')\n",
        "bmx = pd.read_sas('BMX_L.xpt')\n",
        "demo = pd.read_sas('DEMO_L.xpt')\n",
        "df = pd.merge(hdl, bmx, on = 'SEQN')\n",
        "df = pd.merge(df, demo, on = 'SEQN')"
      ],
      "metadata": {
        "id": "YKFat_55cQNE"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 2: Variable Setup and Selection (3 points)\n",
        "\n",
        "For this problem, we will again try to predict individuals that have high-density lipoprotein (HDL) cholesterol of greater than 60. An HDL of 60 **mg/dL** or higher is often viewed as protective against heart disease—this is typically the level you’d like to aim for, if possible. For this task please do the following:\n",
        "\n",
        "1. Create the binary indicator variable. Also, use the following features for predictive purposes: Gender, Age, Weight, Height, BMI, WaistSize, Household Size, and Ethnicity. You may need to refer to the docs to figure out their variable names.\n",
        "\n",
        "\n",
        "\n",
        "*   [HDL_L](https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/HDL_L.htm)\n",
        "*   [DEMO_L](https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DEMO_L.htm)\n",
        "*   [BMX_L](https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/BMX_L.htm)\n",
        "\n",
        "\n",
        "\n",
        "2. **Please** change the variable names to be English-legible but still python variable style.\n",
        "\n",
        "3. Drop all missing values."
      ],
      "metadata": {
        "id": "9WJ_fjDtGpRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'RIAGENDR': 'Gender', 'RIDAGEYR': 'Age', 'BMXWT': 'Weight',\n",
        "                   'BMXHT': 'Height', 'BMXBMI': 'BMI', 'BMXWAIST': 'WaistSize',\n",
        "                   'SDMVPSU': 'Household_Size', 'RIDRETH1': 'Ethnicity'}, inplace=True)\n",
        "\n",
        "my_df = df.copy()\n",
        "my_df['HDL_60'] = (my_df['LBDHDD'] > 60).astype(int)\n",
        "\n",
        "my_df = my_df[['Gender', 'Age', 'Weight', 'Height', 'BMI', 'WaistSize', 'Household_Size', 'Ethnicity', 'HDL_60']]\n",
        "\n",
        "my_df = my_df.dropna()"
      ],
      "metadata": {
        "id": "z-1nqBIXGoPs"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert my_df.shape[0] / df.shape[0] > 0.95"
      ],
      "metadata": {
        "id": "Gjl1m1NRMtnC"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 3: Training + Testing Split (1 point)\n",
        "\n",
        "Please split your data into a train and test set, with 70% of observations in the train set and 30% in the test set.\n",
        "\n",
        "*   Please use the `train_test_split` method.\n",
        "*   Please use the `random_state=42`.\n",
        "*   Please stratify the sampling to include roughly the same distribution of response values in each set. [Why should we stratify?](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold)\n"
      ],
      "metadata": {
        "id": "WC-LVV5xGzF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "_vCJU906Q4JI"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 4: Implementing K-fold CV (2 points)\n",
        "\n",
        "Write a function called KFoldCV that takes in as input 4 arguments:\n",
        "\n",
        "1.   `X` The predictors array.\n",
        "2.   `y` The response variable array.\n",
        "3.   `model`: An sklearn model object on which we can call fit and predict.\n",
        "4.   `K`: An integer representing the number of folds we want to include.\n",
        "\n",
        "and returns the list of classification accuracies for each fold.\n",
        "\n"
      ],
      "metadata": {
        "id": "pann4vE5HrNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def KFoldCV(X, y, model, K=10):\n",
        "  cv = KFold(n_splits=K, shuffle=True, random_state=42)\n",
        "  scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  return scores"
      ],
      "metadata": {
        "id": "8FchjxtyzC2W"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 5 (Code): Execution (2 points)\n",
        "\n",
        "Run your KFoldCV function using Logistic Regression with $K=10$.\n",
        "\n",
        "Please ensure the that the output of the function is visible in the notebook.\n",
        "\n",
        "<u>Note</u>: In the event you get a warning that the model has not reached convergence, add the argument `max_iter=1000` to the LogisticRegression instance."
      ],
      "metadata": {
        "id": "zyow5PvI5AWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "KFoldCV(X_train, y_train, model, K=10)"
      ],
      "metadata": {
        "id": "AMOiomHb38eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb8c90e-097c-496d-af12-336f5901bb3f"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.92857143, 0.8       , 0.88571429, 0.82857143, 0.84285714,\n",
              "       0.88571429, 0.87142857, 0.84285714, 0.87142857, 0.92857143])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 5 (Writing): Generalization (2 points)\n",
        "\n",
        "One motivation for cross-validation is to assess the generalizability of your model on unseen data.\n",
        "\n",
        "Explain in at most two sentences whether you believe your model generalizes well on unseen data. Reference the output of your function to make your case."
      ],
      "metadata": {
        "id": "L52D9v8m5Sbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**\n",
        "\n",
        "$$\\boxed{\\textrm{\n",
        "The cross-validation output shows that our model consistently achieves accuracy. it is likely to generalize well on unseen data.\n",
        "}}$$"
      ],
      "metadata": {
        "id": "YSVwHqDC6I3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 6 (Code): Working with Regularization (3 points)\n",
        "\n",
        "So turns out, if you look at the LogisticRegression module in sklearn, it uses an L2 penalty by default! You can see for yourself on the [documentation page for sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "One problem, we just accepted the default regularization term: C=1.0. How do we know this was the right way to go? Let's see if it even is.\n",
        "\n",
        "Write a function that performs K-Fold validation but with each fold having a different value for $C$. The values considered should range be $10^{-5}, 10^{-4}, \\dots 10^{4}$."
      ],
      "metadata": {
        "id": "fUsRPM7w7uho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# function returns dictionary\n",
        "def KFoldCV_L2(X, y, K=10) -> dict:\n",
        "    C_values = [10**i for i in range(-5, 5)]\n",
        "    results = {}\n",
        "\n",
        "    kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "    for C in C_values:\n",
        "        model = LogisticRegression(C=C, max_iter=1000)\n",
        "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
        "        results[C] = scores\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "acjWMsC08n6g"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KFoldCV_L2(X_train, y_train)"
      ],
      "metadata": {
        "id": "Ebi7-MBlPm7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39d778b-0d8d-47a8-e238-5840b4a374c2"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1e-05: array([0.41428571, 0.51428571, 0.5       , 0.47142857, 0.72857143,\n",
              "        0.51428571, 0.7       , 0.71428571, 0.47142857, 0.51428571]),\n",
              " 0.0001: array([0.58571429, 0.72857143, 0.8       , 0.7       , 0.84285714,\n",
              "        0.74285714, 0.82857143, 0.9       , 0.84285714, 0.85714286]),\n",
              " 0.001: array([0.9       , 0.81428571, 0.88571429, 0.78571429, 0.84285714,\n",
              "        0.91428571, 0.85714286, 0.87142857, 0.9       , 0.91428571]),\n",
              " 0.01: array([0.91428571, 0.82857143, 0.91428571, 0.8       , 0.84285714,\n",
              "        0.91428571, 0.88571429, 0.87142857, 0.88571429, 0.92857143]),\n",
              " 0.1: array([0.92857143, 0.8       , 0.9       , 0.81428571, 0.84285714,\n",
              "        0.88571429, 0.88571429, 0.84285714, 0.87142857, 0.92857143]),\n",
              " 1: array([0.92857143, 0.8       , 0.88571429, 0.82857143, 0.84285714,\n",
              "        0.88571429, 0.87142857, 0.84285714, 0.87142857, 0.92857143]),\n",
              " 10: array([0.92857143, 0.81428571, 0.88571429, 0.82857143, 0.84285714,\n",
              "        0.88571429, 0.87142857, 0.84285714, 0.87142857, 0.92857143]),\n",
              " 100: array([0.92857143, 0.81428571, 0.88571429, 0.82857143, 0.84285714,\n",
              "        0.88571429, 0.87142857, 0.84285714, 0.87142857, 0.92857143]),\n",
              " 1000: array([0.92857143, 0.81428571, 0.88571429, 0.82857143, 0.84285714,\n",
              "        0.88571429, 0.87142857, 0.84285714, 0.87142857, 0.92857143]),\n",
              " 10000: array([0.92857143, 0.81428571, 0.88571429, 0.82857143, 0.84285714,\n",
              "        0.88571429, 0.87142857, 0.84285714, 0.87142857, 0.92857143])}"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 6 (Writing): Evaluation (2 points)\n",
        "\n",
        "Based on your cross-validation, do you believe that regularization plays an effect on the predictive accuracy on unseen accuracy? What level of regularization should we choose?"
      ],
      "metadata": {
        "id": "FU74AZejx6Sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**\n",
        "\n",
        "$$\\boxed{\\textrm{\n",
        "Yes. As *C* becomes larger (i.e., penalizing larger numbers less), the accuracy scores change.  A moderate level of regularization appears optimal\n",
        "}}$$"
      ],
      "metadata": {
        "id": "unRDGKgNyIHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 7 (Code): Train+Val+Test (3 points)\n",
        "\n",
        "Please now retrain your final model (with the best regularization value you found in the last part) on all training data. Then, evaluate your model's performance on the test set."
      ],
      "metadata": {
        "id": "n8b5yqSEdg23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C = 0.01)\n",
        "KFoldCV(X_train, y_train, model, K=10)"
      ],
      "metadata": {
        "id": "xPCkVZyddgiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360bc234-735d-4b9a-881a-0a06a28ab381"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.91428571, 0.82857143, 0.91428571, 0.8       , 0.84285714,\n",
              "       0.91428571, 0.88571429, 0.87142857, 0.88571429, 0.92857143])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 7 (Writing 1): Retraining on Training + Validation Data (1 point)\n",
        "\n",
        "Explain in 1-2 sentences **MAX** why we retrain the model on the merged train+val dataset."
      ],
      "metadata": {
        "id": "BJMmbhEOdCwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**\n",
        "\n",
        "$$\\boxed{\\textrm{\n",
        "We want the model to learn from all available data, leading to a more accurate and reliable estimation of parameters.\n",
        "}}$$"
      ],
      "metadata": {
        "id": "byQOSlhIdFoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 7 (Writing 2): Evalution (1 point)\n",
        "\n",
        "Is logistic regression performing well on this data? Explain in 1-2 sentences **MAX**. **You may need some supporting code for your argument**.\n",
        "\n",
        "<u>Hint</u>: Think about what a trivial baseline would be."
      ],
      "metadata": {
        "id": "iJ8Ljlmhblfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy.fit(X_train, y_train)\n",
        "baseline_accuracy = dummy.score(X_test, y_test)\n",
        "print(\"Trivial baseline accuracy:\", baseline_accuracy)"
      ],
      "metadata": {
        "id": "QGJtGu8ihLAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbb7316-7a42-4d95-8fe7-1ab902ec3ee7"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trivial baseline accuracy: 0.48333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANSWER:**\n",
        "\n",
        "$$\\boxed{\\textrm{\n",
        "The logistic regression is doing much better than a plain dummy classifier.\n",
        "}}$$"
      ],
      "metadata": {
        "id": "xTtnNys5zIT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 8: K-Folds on K-Nearest Neighbors (2 points)\n",
        "\n",
        "Using your KFoldCV function you created in Part 4, please run CV on 2-NN classification."
      ],
      "metadata": {
        "id": "kzC6lrcw1Jif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "knn_scores = KFoldCV(X, y, knn, K=10)\n",
        "\n",
        "print(\"2-NN CV accuracies:\", knn_scores)"
      ],
      "metadata": {
        "id": "4XXDZvr81DJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41acfdd7-28b4-4b5b-ea17-a5423d032c48"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-NN CV accuracies: [0.7  0.78 0.75 0.78 0.74 0.8  0.78 0.84 0.78 0.79]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 9: Finding the Right K (4 points)\n",
        "\n",
        "Similar to what you did for regularized logistic regression, please run a 10-fold CV that assesses model performance on 10 different number of neighbors: [1, 3, 5, 10, 15, 20, 25, 35, 50, 100]. You should attempt to predict each fold with each num_neighbors value.\n",
        "\n",
        "Please write a function called `KFoldCV_NN` that takes as input `X`, `y`, and `K` and returns a dictionary. The dictionary should have the number of neighbors considered as keys and the mean validation accuracy as values.\n",
        "\n"
      ],
      "metadata": {
        "id": "GJiCr1iGjAb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def KFoldCV_NN(X, y, K=10):\n",
        "    num_neighbors = [1, 3, 5, 10, 15, 20, 25, 35, 50, 100]\n",
        "    results = {}  # Initialize dictionary outside the loop\n",
        "    for k in num_neighbors:\n",
        "        model = KNeighborsClassifier(n_neighbors=k)\n",
        "        scores = cross_val_score(model, X, y, scoring='accuracy', cv=K, n_jobs=-1)\n",
        "        results[k] = scores.mean()\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "RT-l5hrdM_og"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KFoldCV_NN(X_train, y_train)"
      ],
      "metadata": {
        "id": "wvDWQHQQNZ93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470d5838-23a6-49e9-fb80-99004654a8c1"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0.7742857142857142,\n",
              " 3: 0.8242857142857142,\n",
              " 5: 0.82,\n",
              " 10: 0.8357142857142857,\n",
              " 15: 0.8585714285714288,\n",
              " 20: 0.8614285714285715,\n",
              " 25: 0.8528571428571429,\n",
              " 35: 0.8571428571428571,\n",
              " 50: 0.8514285714285714,\n",
              " 100: 0.8614285714285714}"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 10: Retraining on Training + Validation Data (2 points)\n",
        "\n",
        "Please retrain your data on both the training and validation set. Make sure you run the KNeighborsClassifier with the best number of neighbors as you determined from the previous part."
      ],
      "metadata": {
        "id": "OQ-lcbsRH_Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "best_knn = KNeighborsClassifier(n_neighbors=20)\n",
        "\n",
        "best_knn.fit(X_train, y_train)\n",
        "\n",
        "predictions = best_knn.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "jkvJwsZ6uaQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042e9314-28dd-45ae-f4cd-44c02573d2c9"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8166666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Part 11: Test Set Evaluation (1 point)\n",
        "\n",
        "\n",
        "Evaluate your final model's performance."
      ],
      "metadata": {
        "id": "QxJsGZiLH_DA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final KNN model with 20 neighbors achieves a test accuracy of approximately 81.67%, which suggests that it generalizes reasonably well on unseen data and performs better than a trivial baseline"
      ],
      "metadata": {
        "id": "b3qr8kcik29w"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}